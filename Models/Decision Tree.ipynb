{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "import keras\n",
    "import sklearn as sk\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>State_Name</th>\n",
       "      <th>District_Name</th>\n",
       "      <th>Crop_Year</th>\n",
       "      <th>Season</th>\n",
       "      <th>Crop</th>\n",
       "      <th>Area</th>\n",
       "      <th>Production</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>145299</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>PHEK</td>\n",
       "      <td>2006</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>Cotton(lint)</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>145322</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>PHEK</td>\n",
       "      <td>2007</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>Cotton(lint)</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>145347</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>PHEK</td>\n",
       "      <td>2008</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>Cotton(lint)</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>145353</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>PHEK</td>\n",
       "      <td>2008</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>Moong(GreenGram)</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>145372</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>PHEK</td>\n",
       "      <td>2008</td>\n",
       "      <td>Rabi</td>\n",
       "      <td>Urad</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 State_Name District_Name  Crop_Year       Season  \\\n",
       "0      145299   Nagaland          PHEK       2006  Kharif        \n",
       "1      145322   Nagaland          PHEK       2007  Kharif        \n",
       "2      145347   Nagaland          PHEK       2008  Kharif        \n",
       "3      145353   Nagaland          PHEK       2008  Kharif        \n",
       "4      145372   Nagaland          PHEK       2008  Rabi          \n",
       "\n",
       "               Crop  Area  Production  \n",
       "0      Cotton(lint)  20.0        10.0  \n",
       "1      Cotton(lint)  20.0        10.0  \n",
       "2      Cotton(lint)  20.0        10.0  \n",
       "3  Moong(GreenGram)  30.0        10.0  \n",
       "4              Urad  20.0        10.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The original dataset that was taken for the analysis\n",
    "df_original = pd.read_csv('crop_production.csv')\n",
    "df_original.head()\n",
    "# The above dataset has a lot of NA values and hence another code was written to clean the dataset and a new csv was generated with no NA values\n",
    "df_clean = pd.read_csv('TrimmedAgro.csv')\n",
    "df_clean.head() # This csv was clean and without any NA values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we shall try the decision tree approach for the continuous variable\n",
    "#import sys\n",
    "#sys.path.append('/home/datta/Documents/5th Sem/DataAnalytics/Project/Final_Project_Codes')\n",
    "from AgroPredictor import DataPreProcessing\n",
    "\n",
    "district_dictionary = DataPreProcessing.NNFriendly()\n",
    "df_decision_tree = pd.read_csv('NNF.csv')\n",
    "df_decision_tree.head()\n",
    "df_decision_tree = df_decision_tree.drop('Unnamed: 0', axis = 1)\n",
    "# Now we try to assign the correct district name given the crop area and prodction.\n",
    "x = df_decision_tree.drop('Crop', axis = 1)\n",
    "y = df_decision_tree['Crop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train,x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "regressor = DecisionTreeRegressor()\n",
    "\n",
    "\n",
    "regressor.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for i in range(len(x_test)):\n",
    "    y_pred.append(int(regressor.predict([x_test.iloc[i].values])[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tst = []\n",
    "for i in range(len(y_test)):\n",
    "    tst.append(y_test.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18.141548646741228"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "meanSquaredError=mean_squared_error(tst, y_pred)\n",
    "print(\"RMSE\")\n",
    "sqrt(meanSquaredError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33.77688380009284"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Accuracy\")\n",
    "metrics.accuracy_score(tst, y_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the area, production and district name separated by commas: 34744,344332,2\n",
      "TUENSANG\n",
      "[ 52.]\n"
     ]
    }
   ],
   "source": [
    "user_input = input(\"Enter the area, production and district name separated by commas: \")\n",
    "input_list = user_input.split(',')\n",
    "numbers = [int(x.strip()) for x in input_list]\n",
    "for key, value in district_dictionary.items():\n",
    "    if numbers[2] == value:\n",
    "        print(key)\n",
    "y_pred = regressor.predict([numbers])\n",
    "print(y_pred)\n",
    "\n",
    "# As we can see that the prediction of the crop based on are , production and district is really good for which crop van be planted we can use decision trees, but only to a certain extent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Length:  193890\n",
      "Dataset Shape:  (193890, 4)\n",
      "Dataset:     Production  Area  Crop  District_Name\n",
      "0        10.0  20.0     1              1\n",
      "1        10.0  20.0     1              1\n",
      "2        10.0  20.0     1              1\n",
      "3        10.0  30.0     2              1\n",
      "4        10.0  20.0     3              1\n",
      "Results Using Gini Index:\n",
      "Predicted values:\n",
      "[24  5  2 ...,  3 30 51]\n",
      "Confusion Matrix:  [[211  17  25 ...,   0   0   0]\n",
      " [ 20 794 270 ...,   0   0   0]\n",
      " [ 21 279 823 ...,   0   0   0]\n",
      " ..., \n",
      " [  0   0   0 ...,   0   0   0]\n",
      " [  0   0   0 ...,   0   1   0]\n",
      " [  0   0   0 ...,   0   0   0]]\n",
      "Accuracy :  36.8662643767\n",
      "Report :               precision    recall  f1-score   support\n",
      "\n",
      "          1       0.24      0.24      0.24       884\n",
      "          2       0.30      0.31      0.31      2545\n",
      "          3       0.31      0.32      0.32      2562\n",
      "          4       0.23      0.25      0.24       673\n",
      "          5       0.39      0.37      0.38      2416\n",
      "          6       0.76      0.77      0.76        88\n",
      "          7       0.23      0.24      0.23      1767\n",
      "          8       0.25      0.25      0.25      1408\n",
      "          9       0.44      0.44      0.44      3433\n",
      "         10       0.31      0.29      0.30      1115\n",
      "         11       0.29      0.31      0.30       720\n",
      "         12       0.14      0.14      0.14       279\n",
      "         13       0.40      0.40      0.40       521\n",
      "         14       0.28      0.29      0.29      1858\n",
      "         15       0.44      0.43      0.44      1147\n",
      "         16       0.33      0.35      0.34       580\n",
      "         17       0.42      0.42      0.42       790\n",
      "         18       0.50      0.52      0.51       311\n",
      "         19       0.18      0.18      0.18       747\n",
      "         20       0.34      0.31      0.33      1033\n",
      "         21       0.29      0.29      0.29      2066\n",
      "         22       0.37      0.39      0.38      1988\n",
      "         23       0.26      0.26      0.26      1292\n",
      "         24       0.26      0.25      0.26       669\n",
      "         25       0.31      0.30      0.30      2374\n",
      "         26       0.32      0.32      0.32      1242\n",
      "         27       0.10      0.10      0.10        73\n",
      "         28       0.50      0.49      0.49      2582\n",
      "         29       0.57      0.57      0.57      1986\n",
      "         30       0.57      0.59      0.58      1194\n",
      "         31       0.17      0.17      0.17        77\n",
      "         32       0.28      0.28      0.28      1244\n",
      "         33       0.28      0.28      0.28      1159\n",
      "         34       0.50      0.49      0.49       834\n",
      "         35       0.57      0.59      0.58      1628\n",
      "         36       0.32      0.31      0.31      1792\n",
      "         37       0.25      0.24      0.25       908\n",
      "         38       0.43      0.45      0.44       975\n",
      "         39       0.21      0.22      0.21       138\n",
      "         40       0.27      0.30      0.28       430\n",
      "         41       0.46      0.35      0.40       122\n",
      "         42       0.09      0.10      0.10       128\n",
      "         43       0.27      0.27      0.27      1022\n",
      "         44       0.46      0.47      0.47       276\n",
      "         45       0.61      0.62      0.61       243\n",
      "         46       0.15      0.17      0.16        69\n",
      "         47       0.00      0.00      0.00        14\n",
      "         48       0.36      0.32      0.34        62\n",
      "         49       0.13      0.10      0.11       183\n",
      "         50       0.42      0.52      0.47        33\n",
      "         51       0.08      0.07      0.07        44\n",
      "         52       0.37      0.37      0.37       302\n",
      "         53       0.44      0.44      0.44      1173\n",
      "         54       0.18      0.10      0.13        29\n",
      "         55       0.50      0.50      0.50       472\n",
      "         56       0.18      0.18      0.18       382\n",
      "         57       0.10      0.11      0.11       134\n",
      "         58       0.41      0.46      0.43       378\n",
      "         59       0.10      0.06      0.08        31\n",
      "         60       0.78      0.74      0.76      1255\n",
      "         61       0.00      0.00      0.00         1\n",
      "         62       0.38      0.39      0.39       122\n",
      "         63       0.20      0.17      0.18        54\n",
      "         64       0.05      0.10      0.07        21\n",
      "         65       0.64      0.59      0.61       377\n",
      "         66       0.05      0.05      0.05        22\n",
      "         67       0.00      0.00      0.00        12\n",
      "         68       0.14      0.20      0.17         5\n",
      "         69       0.61      0.60      0.60       779\n",
      "         70       0.12      0.20      0.15        40\n",
      "         71       0.14      0.14      0.14        37\n",
      "         72       0.29      0.35      0.32        20\n",
      "         73       0.00      0.00      0.00         4\n",
      "         74       0.53      0.51      0.52       230\n",
      "         75       0.00      0.00      0.00         5\n",
      "         76       0.00      0.00      0.00         3\n",
      "         77       0.17      0.17      0.17        64\n",
      "         78       0.00      0.00      0.00        10\n",
      "         79       0.00      0.00      0.00         7\n",
      "         80       0.22      0.14      0.17        36\n",
      "         81       0.13      0.10      0.11        39\n",
      "         82       0.50      0.25      0.33         4\n",
      "         83       0.03      0.03      0.03        31\n",
      "         84       0.00      0.00      0.00        15\n",
      "         85       0.16      0.22      0.18        60\n",
      "         86       0.12      0.07      0.09        28\n",
      "         87       0.02      0.01      0.01        93\n",
      "         88       0.25      0.33      0.29         9\n",
      "         89       0.00      0.00      0.00         3\n",
      "         90       0.36      0.52      0.43        61\n",
      "         91       0.00      0.00      0.00         3\n",
      "         92       0.00      0.00      0.00        10\n",
      "         93       0.75      0.33      0.46         9\n",
      "         94       0.00      0.00      0.00         3\n",
      "         95       0.00      0.00      0.00         6\n",
      "         96       0.33      0.25      0.29         4\n",
      "         97       0.20      0.20      0.20         5\n",
      "         98       0.50      0.47      0.48        15\n",
      "         99       0.50      0.20      0.29         5\n",
      "        100       0.25      0.18      0.21        17\n",
      "        101       0.25      0.17      0.20         6\n",
      "        102       0.20      0.33      0.25         3\n",
      "        103       0.00      0.00      0.00         2\n",
      "        104       0.50      0.50      0.50         2\n",
      "        105       0.00      0.00      0.00         5\n",
      "\n",
      "avg / total       0.37      0.37      0.37     58167\n",
      "\n",
      "Results Using Entropy:\n",
      "Predicted values:\n",
      "[24  5 56 ...,  3 30  9]\n",
      "Confusion Matrix:  [[199  19  26 ...,   0   0   0]\n",
      " [ 16 807 296 ...,   0   0   0]\n",
      " [ 31 268 846 ...,   0   0   0]\n",
      " ..., \n",
      " [  0   0   0 ...,   0   0   0]\n",
      " [  0   0   0 ...,   0   0   0]\n",
      " [  0   0   0 ...,   1   0   0]]\n",
      "Accuracy :  37.1430536215\n",
      "Report :               precision    recall  f1-score   support\n",
      "\n",
      "          1       0.24      0.23      0.23       884\n",
      "          2       0.31      0.32      0.31      2545\n",
      "          3       0.31      0.33      0.32      2562\n",
      "          4       0.23      0.25      0.24       673\n",
      "          5       0.41      0.39      0.40      2416\n",
      "          6       0.83      0.77      0.80        88\n",
      "          7       0.26      0.27      0.26      1767\n",
      "          8       0.26      0.27      0.26      1408\n",
      "          9       0.44      0.43      0.44      3433\n",
      "         10       0.34      0.31      0.32      1115\n",
      "         11       0.30      0.30      0.30       720\n",
      "         12       0.20      0.19      0.20       279\n",
      "         13       0.41      0.41      0.41       521\n",
      "         14       0.30      0.29      0.30      1858\n",
      "         15       0.44      0.41      0.42      1147\n",
      "         16       0.34      0.34      0.34       580\n",
      "         17       0.40      0.42      0.41       790\n",
      "         18       0.49      0.51      0.50       311\n",
      "         19       0.19      0.19      0.19       747\n",
      "         20       0.32      0.29      0.31      1033\n",
      "         21       0.29      0.29      0.29      2066\n",
      "         22       0.40      0.41      0.41      1988\n",
      "         23       0.25      0.25      0.25      1292\n",
      "         24       0.24      0.24      0.24       669\n",
      "         25       0.30      0.30      0.30      2374\n",
      "         26       0.34      0.33      0.33      1242\n",
      "         27       0.13      0.15      0.14        73\n",
      "         28       0.50      0.50      0.50      2582\n",
      "         29       0.56      0.56      0.56      1986\n",
      "         30       0.56      0.56      0.56      1194\n",
      "         31       0.16      0.18      0.17        77\n",
      "         32       0.28      0.28      0.28      1244\n",
      "         33       0.31      0.29      0.30      1159\n",
      "         34       0.50      0.47      0.48       834\n",
      "         35       0.60      0.59      0.59      1628\n",
      "         36       0.32      0.31      0.31      1792\n",
      "         37       0.23      0.23      0.23       908\n",
      "         38       0.40      0.43      0.42       975\n",
      "         39       0.27      0.30      0.29       138\n",
      "         40       0.26      0.29      0.27       430\n",
      "         41       0.47      0.40      0.43       122\n",
      "         42       0.09      0.09      0.09       128\n",
      "         43       0.27      0.27      0.27      1022\n",
      "         44       0.47      0.47      0.47       276\n",
      "         45       0.57      0.60      0.59       243\n",
      "         46       0.10      0.13      0.12        69\n",
      "         47       0.12      0.07      0.09        14\n",
      "         48       0.30      0.42      0.35        62\n",
      "         49       0.11      0.08      0.09       183\n",
      "         50       0.43      0.45      0.44        33\n",
      "         51       0.07      0.07      0.07        44\n",
      "         52       0.32      0.34      0.33       302\n",
      "         53       0.42      0.42      0.42      1173\n",
      "         54       0.10      0.10      0.10        29\n",
      "         55       0.50      0.48      0.49       472\n",
      "         56       0.23      0.23      0.23       382\n",
      "         57       0.09      0.09      0.09       134\n",
      "         58       0.46      0.45      0.46       378\n",
      "         59       0.10      0.06      0.08        31\n",
      "         60       0.77      0.77      0.77      1255\n",
      "         61       0.00      0.00      0.00         1\n",
      "         62       0.43      0.41      0.42       122\n",
      "         63       0.12      0.11      0.12        54\n",
      "         64       0.03      0.05      0.04        21\n",
      "         65       0.55      0.58      0.56       377\n",
      "         66       0.09      0.09      0.09        22\n",
      "         67       0.00      0.00      0.00        12\n",
      "         68       0.00      0.00      0.00         5\n",
      "         69       0.62      0.61      0.62       779\n",
      "         70       0.13      0.17      0.15        40\n",
      "         71       0.13      0.14      0.13        37\n",
      "         72       0.53      0.40      0.46        20\n",
      "         73       0.00      0.00      0.00         4\n",
      "         74       0.51      0.51      0.51       230\n",
      "         75       0.00      0.00      0.00         5\n",
      "         76       0.00      0.00      0.00         3\n",
      "         77       0.16      0.19      0.17        64\n",
      "         78       0.15      0.20      0.17        10\n",
      "         79       0.00      0.00      0.00         7\n",
      "         80       0.12      0.08      0.10        36\n",
      "         81       0.11      0.08      0.09        39\n",
      "         82       1.00      0.25      0.40         4\n",
      "         83       0.03      0.03      0.03        31\n",
      "         84       0.00      0.00      0.00        15\n",
      "         85       0.12      0.15      0.13        60\n",
      "         86       0.08      0.04      0.05        28\n",
      "         87       0.05      0.04      0.05        93\n",
      "         88       0.20      0.22      0.21         9\n",
      "         89       0.00      0.00      0.00         3\n",
      "         90       0.35      0.46      0.40        61\n",
      "         91       0.00      0.00      0.00         3\n",
      "         92       0.00      0.00      0.00        10\n",
      "         93       0.80      0.44      0.57         9\n",
      "         94       0.10      0.33      0.15         3\n",
      "         95       0.00      0.00      0.00         6\n",
      "         96       1.00      0.50      0.67         4\n",
      "         97       0.25      0.40      0.31         5\n",
      "         98       0.56      0.60      0.58        15\n",
      "         99       0.17      0.20      0.18         5\n",
      "        100       0.20      0.12      0.15        17\n",
      "        101       0.29      0.33      0.31         6\n",
      "        102       0.25      0.33      0.29         3\n",
      "        103       0.00      0.00      0.00         2\n",
      "        104       0.00      0.00      0.00         2\n",
      "        105       0.00      0.00      0.00         5\n",
      "\n",
      "avg / total       0.37      0.37      0.37     58167\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/datta/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Run this program on your local python\n",
    "# interpreter, provided you have installed\n",
    "# the required libraries.\n",
    "\n",
    "# Importing the required packages\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report \n",
    "  \n",
    "# Function importing Dataset \n",
    "def importdata():\n",
    "    balance_data = pd.read_csv('NNF.csv') \n",
    "    balance_data = balance_data.drop('Unnamed: 0', axis = 1)\n",
    "    # Printing the dataset shape \n",
    "    print (\"Dataset Length: \", len(balance_data)) \n",
    "    print (\"Dataset Shape: \", balance_data.shape) \n",
    "    # Printing the dataset obseravtions \n",
    "    print (\"Dataset: \",balance_data.head()) \n",
    "    return balance_data \n",
    "  \n",
    "# Function to split the dataset \n",
    "def splitdataset(balance_data): \n",
    "  \n",
    "    # Separating the target variable \n",
    "    X = balance_data.drop('Crop', axis = 1)\n",
    "    Y = balance_data['Crop']\n",
    "  \n",
    "    # Spliting the dataset into train and test \n",
    "    X_train, X_test, y_train, y_test = train_test_split(  \n",
    "    X, Y, test_size = 0.3, random_state = 100) \n",
    "      \n",
    "    return X, Y, X_train, X_test, y_train, y_test \n",
    "      \n",
    "# Function to perform training with giniIndex. \n",
    "def train_using_gini(X_train, X_test, y_train): \n",
    "  \n",
    "    # Creating the classifier object \n",
    "    clf_gini = DecisionTreeClassifier(criterion = \"gini\", \n",
    "            random_state = 100) \n",
    "  \n",
    "    # Performing training \n",
    "    clf_gini.fit(X_train, y_train) \n",
    "    return clf_gini \n",
    "      \n",
    "# Function to perform training with entropy. \n",
    "def tarin_using_entropy(X_train, X_test, y_train): \n",
    "  \n",
    "    # Decision tree with entropy \n",
    "    clf_entropy = DecisionTreeClassifier( \n",
    "            criterion = \"entropy\", random_state = 100) \n",
    "  \n",
    "    # Performing training \n",
    "    clf_entropy.fit(X_train, y_train) \n",
    "    return clf_entropy \n",
    "  \n",
    "  \n",
    "# Function to make predictions \n",
    "def prediction(X_test, clf_object): \n",
    "  \n",
    "    # Predicton on test with giniIndex \n",
    "    y_pred = clf_object.predict(X_test) \n",
    "    print(\"Predicted values:\") \n",
    "    print(y_pred) \n",
    "    return y_pred \n",
    "      \n",
    "# Function to calculate accuracy \n",
    "def cal_accuracy(y_test, y_pred): \n",
    "      \n",
    "    print(\"Confusion Matrix: \", \n",
    "        confusion_matrix(y_test, y_pred)) \n",
    "      \n",
    "    print (\"Accuracy : \", \n",
    "    accuracy_score(y_test,y_pred)*100) \n",
    "      \n",
    "    print(\"Report : \", \n",
    "    classification_report(y_test, y_pred)) \n",
    "  \n",
    "# Driver code \n",
    "def main(): \n",
    "      \n",
    "    # Building Phase \n",
    "    data = importdata() \n",
    "    X, Y, X_train, X_test, y_train, y_test = splitdataset(data) \n",
    "    clf_gini = train_using_gini(X_train, X_test, y_train) \n",
    "    clf_entropy = tarin_using_entropy(X_train, X_test, y_train) \n",
    "      \n",
    "    # Operational Phase \n",
    "    print(\"Results Using Gini Index:\") \n",
    "      \n",
    "    # Prediction using gini \n",
    "    y_pred_gini = prediction(X_test, clf_gini) \n",
    "    cal_accuracy(y_test, y_pred_gini) \n",
    "      \n",
    "    print(\"Results Using Entropy:\") \n",
    "    # Prediction using entropy \n",
    "    y_pred_entropy = prediction(X_test, clf_entropy) \n",
    "    cal_accuracy(y_test, y_pred_entropy) \n",
    "      \n",
    "      \n",
    "# Calling main function \n",
    "if __name__==\"__main__\": \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
